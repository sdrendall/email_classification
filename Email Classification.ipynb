{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import email\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk.corpus import stopwords\n",
    "from tools import cat_parser\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the list of data files from the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "email_paths = [\n",
    "    os.path.join(root, filename) for root, _, filenames in os.walk(data_path)\n",
    "        for filename in filenames\n",
    "        if filename.endswith('.txt')\n",
    "][1:] # first file found is the categories.txt file detailing the categories\n",
    "category_paths = map(lambda s: str.replace(s, '.txt', '.cats'), email_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constants that will be used for memory allocation and parameterizing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(email_paths)\n",
    "n_categories = 8\n",
    "n_features = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the email data and remove punctuation and stopwords from the email bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "def clean_email_body(body):\n",
    "    punctuation_removed = re.sub(\n",
    "        \"[^a-zA-Z]\",  \n",
    "        \" \",  \n",
    "        body \n",
    "    )\n",
    "    all_lowercase = punctuation_removed.lower()\n",
    "    words = all_lowercase.split()\n",
    "    meaningful_words = [word for word in words if word not in stops]\n",
    "    return \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_files = it.imap(open, email_paths)\n",
    "email_msgs = it.imap(email.message_from_file, email_files)\n",
    "email_bodies = (msg.get_payload() for msg in email_msgs)\n",
    "email_bodies_clean = map(clean_email_body, email_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=None,\n",
    "    preprocessor=None,\n",
    "    stop_words=None,\n",
    "    max_features=n_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(\n",
    "#     analyzer='word',\n",
    "#     ngram_range=(1, 1),\n",
    "#     stop_words=None,\n",
    "#     max_features=n_features\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_body_features = vectorizer.fit_transform(email_bodies_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categories_as_vector(cata_dict_list):\n",
    "    return np.asarray([cata[1][0] for cata in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = map(cat_parser.parse_file, category_paths)\n",
    "cat_vec = categories_as_vector(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, we're only going to assign a single category to each email, this is hard enough as it is\n",
    "#  hence, cata[1][0]\n",
    "cat_vec = np.asarray([cata[1][0] for cata in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_class = 1\n",
    "cat_vec_targeted = cat_vec == target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_train, feat_test, cat_train, cat_test = train_test_split(\n",
    "    email_body_features, \n",
    "    cat_vec_targeted, \n",
    "    test_size=0.2,\n",
    "    random_state=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=500,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_reg = LogisticRegression(\n",
    "    class_weight='balanced', \n",
    "    solver='lbfgs',\n",
    "    max_iter=500\n",
    ")\n",
    "model_log_reg.fit(feat_train, cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983100661278\n",
      "0.791788856305\n"
     ]
    }
   ],
   "source": [
    "print model_log_reg.score(feat_train, cat_train)\n",
    "print model_log_reg.score(feat_test, cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786001386001\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(cat_test, model_log_reg.predict(feat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
